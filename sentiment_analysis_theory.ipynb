{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e103735",
   "metadata": {},
   "source": [
    "# Customer Review Sentiment Analysis: Theoretical Framework\n",
    "\n",
    "**Author:** Data Science Team | **Date:** January 2026\n",
    "\n",
    "---\n",
    "\n",
    "## Introduction to Sentiment Analysis\n",
    "\n",
    "Sentiment analysis, also known as opinion mining, is a natural language processing technique that identifies and extracts subjective information from text. This project implements VADER (Valence Aware Dictionary and sEntiment Reasoner), a lexicon and rule-based sentiment analysis tool specifically designed for social media and short-form text.\n",
    "\n",
    "## Core Theoretical Concepts\n",
    "\n",
    "### 1. VADER Algorithm Foundation\n",
    "\n",
    "VADER operates on a pre-constructed sentiment lexicon where each word carries a valence score indicating emotional intensity. The algorithm calculates a compound score ranging from -1 (extremely negative) to +1 (extremely positive) through normalized aggregation of individual word sentiments.\n",
    "\n",
    "**Key Advantages:**\n",
    "- **No Training Required:** Works immediately without machine learning model training\n",
    "- **Context Awareness:** Handles negations (\"not good\"), intensifiers (\"very happy\"), and punctuation emphasis\n",
    "- **Social Media Optimized:** Interprets emoticons, capitalization, and informal language\n",
    "- **Computational Efficiency:** Linear time complexity enables real-time analysis\n",
    "\n",
    "### 2. Text Preprocessing Pipeline\n",
    "\n",
    "Preprocessing transforms raw text into analyzable format through normalization, tokenization, and cleaning. Lowercasing reduces vocabulary dimensionality by approximately 50% based on Zipf's Law, which states that word frequency follows a power distribution. Removing special characters focuses analysis on semantic content while preserving linguistic markers that VADER interprets.\n",
    "\n",
    "### 3. Statistical Correlation Analysis\n",
    "\n",
    "Pearson correlation coefficient measures linear relationships between variables, ranging from -1 to +1. In this analysis, we examine whether review length correlates with sentiment polarity. The p-value determines statistical significance; values below 0.05 indicate 95% confidence that observed patterns are non-random. Cohen's guidelines classify correlation strength: negligible (0-0.1), weak (0.1-0.3), moderate (0.3-0.5), and strong (0.5+).\n",
    "\n",
    "### 4. Information Theory Applications\n",
    "\n",
    "Shannon entropy quantifies information uncertainty in probability distributions. For sentiment classification, entropy reveals distribution balance across categories. High entropy (approaching maximum) indicates even distribution between positive, negative, and neutral sentiments, suggesting diverse customer opinions. Low entropy indicates skewed distributions, reflecting consensus perception.\n",
    "\n",
    "**Business Interpretation:**\n",
    "- **Low Entropy:** Clear brand perception, consistent customer experience\n",
    "- **High Entropy:** Mixed opinions, potential market segmentation opportunities\n",
    "\n",
    "### 5. Visualization Theory\n",
    "\n",
    "Word clouds employ logarithmic scaling based on Weber-Fechner psychophysical law: perceived stimulus intensity relates logarithmically to actual intensity. This prevents dominant high-frequency words from obscuring important lower-frequency terms, creating balanced visual information density. Color schemes leverage universal psychological associations: green (positive), red (negative), orange (neutral).\n",
    "\n",
    "### 6. Classification Boundaries\n",
    "\n",
    "Sentiment categories use empirically-derived thresholds: scores below -0.05 classify as negative, above +0.05 as positive, and between as neutral. These boundaries emerged from VADER validation studies analyzing human-annotated sentiment in diverse text corpora. The neutral zone acknowledges ambiguous sentiment where mixed or insufficient emotional indicators exist.\n",
    "\n",
    "## Methodology Summary\n",
    "\n",
    "This pipeline integrates multiple disciplines: computational linguistics for text processing, statistical analysis for pattern detection, information theory for distribution characterization, and visual analytics for insight communication. Each component contributes complementary perspectives, transforming unstructured text into actionable business intelligence while maintaining theoretical rigor and reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "**Word Count:** 497 words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31eb27f",
   "metadata": {},
   "source": [
    "## Implementation: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484faf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "# Plotly for interactive visualizations\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# NLTK for sentiment analysis\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from wordcloud import WordCloud\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Configure plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Download NLTK data\n",
    "try:\n",
    "    nltk.data.find('vader_lexicon')\n",
    "except LookupError:\n",
    "    nltk.download('vader_lexicon', quiet=True)\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a727db92",
   "metadata": {},
   "source": [
    "## Load and Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47b453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('reviews_dataset.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nMissing Values:\\n{df.isnull().sum()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289d83a4",
   "metadata": {},
   "source": [
    "## Text Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca11c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Feature engineering: review length\n",
    "df['review_length'] = df['review_text'].str.len()\n",
    "\n",
    "# Text normalization\n",
    "df['clean_review'] = (\n",
    "    df['review_text']\n",
    "    .str.lower()\n",
    "    .str.replace(r'[^a-z\\s]', '', regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "print(f\"✓ Preprocessing complete\")\n",
    "print(f\"Average review length: {df['review_length'].mean():.1f} characters\")\n",
    "df[['review_text', 'clean_review', 'review_length']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33805e9",
   "metadata": {},
   "source": [
    "## VADER Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize VADER analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Calculate sentiment scores\n",
    "df['sentiment_score'] = df['clean_review'].apply(\n",
    "    lambda x: sia.polarity_scores(x)['compound']\n",
    ")\n",
    "\n",
    "# Classify sentiments\n",
    "df['sentiment_category'] = pd.cut(\n",
    "    df['sentiment_score'],\n",
    "    bins=[-1.0, -0.05, 0.05, 1.0],\n",
    "    labels=['Negative', 'Neutral', 'Positive']\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"Sentiment Distribution:\")\n",
    "print(df['sentiment_category'].value_counts())\n",
    "print(f\"\\nSentiment Score Statistics:\")\n",
    "print(df['sentiment_score'].describe())\n",
    "df[['review_text', 'sentiment_score', 'sentiment_category']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8818c1",
   "metadata": {},
   "source": [
    "## Statistical Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f485071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation test\n",
    "correlation, p_value = pearsonr(df['review_length'], df['sentiment_score'])\n",
    "\n",
    "print(f\"Correlation Analysis: Review Length vs Sentiment Score\")\n",
    "print(f\"Correlation coefficient (r): {correlation:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"R-squared: {correlation**2:.4f}\")\n",
    "\n",
    "# Interpret strength\n",
    "if abs(correlation) < 0.1:\n",
    "    strength = \"negligible\"\n",
    "elif abs(correlation) < 0.3:\n",
    "    strength = \"weak\"\n",
    "elif abs(correlation) < 0.5:\n",
    "    strength = \"moderate\"\n",
    "else:\n",
    "    strength = \"strong\"\n",
    "\n",
    "print(f\"\\nInterpretation: {strength.capitalize()} correlation\")\n",
    "print(f\"Statistically significant: {'Yes' if p_value < 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c1da5b",
   "metadata": {},
   "source": [
    "## Information Entropy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac544d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Shannon entropy\n",
    "sentiment_counts = df['sentiment_category'].value_counts()\n",
    "probabilities = sentiment_counts / len(df)\n",
    "entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))\n",
    "max_entropy = np.log2(3)  # Maximum for 3 categories\n",
    "\n",
    "print(f\"Shannon Entropy: {entropy:.4f} bits\")\n",
    "print(f\"Maximum Entropy: {max_entropy:.4f} bits\")\n",
    "print(f\"Normalized Entropy: {entropy/max_entropy:.4f}\")\n",
    "print(f\"\\nInterpretation:\")\n",
    "if entropy/max_entropy > 0.8:\n",
    "    print(\"High entropy - diverse opinions across sentiment categories\")\n",
    "else:\n",
    "    print(\"Low entropy - consensus in customer sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55305391",
   "metadata": {},
   "source": [
    "## Generate Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70204297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word clouds for each sentiment category\n",
    "categories = ['Positive', 'Neutral', 'Negative']\n",
    "color_schemes = {'Positive': 'Greens', 'Neutral': 'Oranges', 'Negative': 'Reds'}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, category in enumerate(categories):\n",
    "    reviews = df[df['sentiment_category'] == category]['clean_review']\n",
    "    text = \" \".join(reviews.dropna())\n",
    "    \n",
    "    if text.strip():\n",
    "        wordcloud = WordCloud(\n",
    "            width=600, \n",
    "            height=400,\n",
    "            background_color='white',\n",
    "            colormap=color_schemes[category],\n",
    "            max_words=50\n",
    "        ).generate(text)\n",
    "        \n",
    "        axes[idx].imshow(wordcloud, interpolation='bilinear')\n",
    "        axes[idx].set_title(f'{category} Reviews ({len(reviews)} reviews)', \n",
    "                           fontsize=14, fontweight='bold')\n",
    "        axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print(\"✓ Word clouds generated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e39d1f2",
   "metadata": {},
   "source": [
    "## Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded310bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "os.makedirs('output', exist_ok=True)\n",
    "\n",
    "# Export enriched dataset\n",
    "df.to_csv('output/reviews_with_sentiment.csv', index=False)\n",
    "print(\"✓ Enriched dataset saved: output/reviews_with_sentiment.csv\")\n",
    "\n",
    "# Create summary report\n",
    "summary = {\n",
    "    'Metric': ['Total Reviews', 'Positive %', 'Negative %', 'Neutral %', \n",
    "               'Mean Sentiment', 'Correlation (Length vs Sentiment)', 'Entropy'],\n",
    "    'Value': [\n",
    "        len(df),\n",
    "        f\"{(sentiment_counts.get('Positive', 0) / len(df) * 100):.2f}%\",\n",
    "        f\"{(sentiment_counts.get('Negative', 0) / len(df) * 100):.2f}%\",\n",
    "        f\"{(sentiment_counts.get('Neutral', 0) / len(df) * 100):.2f}%\",\n",
    "        f\"{df['sentiment_score'].mean():.4f}\",\n",
    "        f\"{correlation:.4f}\",\n",
    "        f\"{entropy:.4f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.to_csv('output/analysis_summary.csv', index=False)\n",
    "print(\"✓ Summary report saved: output/analysis_summary.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
